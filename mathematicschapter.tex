\chapter{Mathematics of Modulo7}
\label{sec:mir math}

\noindent The following sections describe the mathematical concepts used and implemented in Modulo7.

\section{Vector Space Models of Music}

\noindent In traditional text based information retrieval retrieval systems, documents are indexed and a vector space representation of documents are created. Typical approaches for counting term frequencies or some weighting scheme like Term Frequency-Inverse Document Frequency Approach (TF-IDF). Analogous to text based IR, Music data can also be expressed as a vector space based on the approach taken. Some of these approaches are taken from the SIMILIE \cite{similietechnicalmanual} but generalized for polyphonic music. Many approaches are novel based on the author's music theoretic studies. 

\subsection{Vector Space Models for Monophonic Music}

\noindent Certain vector space models are with respect to a single voice. This allows vector space models to be represented as arrays with simple methods of computation that can be applied on top of it. First define pitch as a real number/string depending on context such that at given instant time $t_i$ either frequency $p_i$ is being played or its note representation $p_i$ is being played. With this simple definition of pitch and onset time we can define our vector space models as follows:-\\
 
\noindent \textbf{Pitch Vector:} A voice can be expressed as a sequence of pitches $n_i$ = ($p_i, t_i$) where $p_i$ is the pitch and/or the set of pitches at instant of time $t_i$. The symbolic representation of music essentially discretizes these values from music sources and hence a vector representation can be made. A voice V can be represented as a vector :-

\begin{equation}
P = <n_1, n_2, ... n_n>
\end{equation}

\noindent A similar vector representation could be when the time information is eschewed in favor on only the pitches. This vector is called the raw pitch vector and is denoted as the follows :-

\begin{equation} \label{eq:rawpitch}
R = <p_1, p_2, ..., p_n>
\end{equation}

\noindent \textbf{Pitch Interval Vector:} Another way to look at elements is the interval spacing between elements. This is same as the interval concept in the music theory chapter. Mathematically an interval is defined as $\Delta p_i = p_i - p_{i-1}$. And thus an pitch interval vector is defined as :-

\begin{equation}
PI = <\Delta p_1, \Delta p_2, ... , \Delta p_n>
\end{equation}

\noindent \textbf{Rhythmically weighted Pitch Interval Vector:} In order to include the rhythmic information in the pitch interval Vector, define rhythmically weighted pitch as $rp_i = \Delta p_i \times t_i$. Now the rhythmically weighted pitch vector can be represented as:-

\begin{equation}
RPI = <rp_1, rp_2, ... rp_n>
\end{equation}

\noindent \textbf{Normalized Tonal Histogram Vector:} The tonal histogram is a vector or map of 12 distinct intervals present in western music theory. Each position in the vector corresponds to the total number of times that interval has occurred in a voice. Mathematically define $\Delta P^{voice_j} = \sum_{i=1}^{len(voice)} p_i^{voice_j}$. Define interval fraction as : $\Delta p^f_i = \frac{\Delta p_i}{\Delta P^{voice}}$. Thus we can define the normalized tonal histogram vector as :-

\begin{equation}
NTH = <\Delta p^f_1, \Delta p^f_2, ... , \Delta p^f_n>
\end{equation}

\subsection{Vector Space Models for Polyphonic Music} 

\noindent While vector space models per voices are useful in single melody similarity, its not enough to ascertain similarities or compute statistics about songs when songs have more than one voice. As such certain extensions are proposed to the voice vector representation that allow for similarity computations for polyphonic music.\\\\
\noindent \textbf{Normalized Song Tonal Histogram Vector:}  \noindent Consider the normalized tonal histogram in section. We can define the cumulative intervals across all voices as \\ $\Delta P_{song} = \sum_{i = 1}^{num(voices)} \Delta P^{voice_j}$. Define interval fraction over song as $\Delta p^{fs}_i = \frac{\Delta p_i}{\Delta P^{song}}$   Now define the normalized tonal histogram vector for the song as the follows:-

\begin{equation}
NSTH = <\Delta p^{fs}_1, \Delta p^{fs}_2, ... , \Delta p^{fs}_n>
\end{equation}

\section{Similarity Measures}

\noindent Similarity is defined in Modulo7 as a function which takes as input two voices or songs and outputs a value between 0 to 1 where 0 stands for least similar and 1 stands for most similar. Similarity measures are a cornerstone of recommendations and many recommender engines are based on rank similarity measures for different criteria. Mathematically :-
\begin{equation}
Sim_{song}(S_1, S_2) \in (0, 1)
\end{equation}
\begin{equation}
Sim_{voice}(V_1, V_2) \in (0, 1)
\end{equation}

\subsection{Similarity Measures for Monophonic Music}

\noindent Similarity measures are different concepts for monophonic and polyphonic music as it stems from comparing different vector representations. For the following sections assume vectors of equal length. In a further section \ref{sim:unequal} we extend standard similarity measures to vectors of unequal length. \\

\noindent \textbf{Edit Distance on Raw Pitch Vector Representation:} Consider the raw pitch vector in equation \ref{eq:rawpitch}. This vector is essentially a vector of tokens or equivalently a string. Hence standard edit distance algorithms in normal text IR can be applied to it (e.g Leveinstein Distance, Wagnerâ€“Fischer algorithm etc \cite{simtour}).

\subsection{Similarity Measures for Polyphonic Music}

\noindent In order to incorporate 

\subsection{Similarity of vectors of unequal length} \label{sim:unequal}

\noindent Its almost certain that two voices will  never have the same length. Hence its important at this point to ascertain how to map similarity measures to unequal length voices. Consider two voices $\vec{A}$ and $\vec{B}$. Without loss of generality assume $len(A) > len(B)$. Let i be an index running from 0 to len(A) - len(B) and $C_i$ be defined as the sub component of a melody (also called submelody) which contains voice elements $A[i] \ to \ A[i + len(B)]$. Then similarity measure $S_{unequal}(S_{original}, A, B)$ can be defined as the following

\begin{equation}
S_{unequal}(S_{original}, A, B) = max_i (C_i, B) \text{ where } i \in \{0, len(A) - len(B)\}
\end{equation}

\noindent This procedure is a basic modification of the concept of Horizontal Shifting\cite{similietechnicalmanual}. Here we keep shifting the smaller melody along the longer melody successively for faster computation. This technique is best used when one melody's vector space representation is completely contained in another (for an example a phrase of a voice compared with a voice itself).

\subsection{Meta Data based similarity}

\noindent All the similarity measures considered so far is based on similarity on voices and sets of voices in a a song. However there are other global properties of a song such as the key signature or  the time signature of a song. This global information can give us context about a song's particular characteristics (for example songs in Minor scale are generally sadder than songs in the Major scale). Hence estimates can be more quickly derived by comparing meta data features rather than voices (whose computation). These similarity measures can be used for a additional purposes(for example completing incomplete meta data). 

\noindent \textbf{text}

\subsection{Tonal Similarity}



